{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20a8b9bd",
   "metadata": {},
   "source": [
    "![deelema](../img/DeeLeMa.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2253705-2a4f-42da-a1bd-4da1fe7647a5",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc133f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Uniform\n",
    "from torch.optim.lr_scheduler import OneCycleLR, PolynomialLR, CosineAnnealingLR\n",
    "\n",
    "import lightning as pl\n",
    "from lightning import Trainer\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "PATH_DATASETS = \".\"\n",
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "BATCH_SIZE = 2048 if AVAIL_GPUS else 64\n",
    "# BATCH_SIZE=1\n",
    "\n",
    "plt.rc('font', size=20)        # 기본 폰트 크기\n",
    "plt.rc('axes', labelsize=20)   # x,y축 label 폰트 크기\n",
    "plt.rc('xtick', labelsize=20)  # x축 눈금 폰트 크기 \n",
    "plt.rc('ytick', labelsize=20)  # y축 눈금 폰트 크기\n",
    "plt.rc('legend', fontsize=20)  # 범례 폰트 크기\n",
    "plt.rc('figure', titlesize=20) # figure title 폰트 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8226b736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 8407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8407"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(8407)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bb37aab-8359-4ef2-8f38-b531af588ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a0012fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyData(Dataset):\n",
    "    def __init__(self, p_A, p_a, p_B, p_b, q_C, q_c):\n",
    "        self.X = torch.column_stack([p_A, p_a, p_B, p_b])\n",
    "        self.q_C = q_C\n",
    "        self.q_c = q_c\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.q_C[idx], self.q_c[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c977e6",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec852742",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/\"\n",
    "PROCESS   = \"toy\"\n",
    "np_data   = np.load(DATA_PATH + PROCESS + '_array_new.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae0dd6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa1 = np_data['b1']\n",
    "pa2 = np_data['b2']\n",
    "pb1 = np_data['l2']\n",
    "pb2 = np_data['l1']\n",
    "qc1 = np_data['nu1']\n",
    "qc2 = np_data['nu2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abd82ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_mass_sq(p):\n",
    "    return p[:,0]**2 - p[:,1]**2 - p[:,2]**2 - p[:,3]**2\n",
    "\n",
    "g = np.array([1,-1,-1,-1])\n",
    "def Mass(p, ax=1):\n",
    "    return torch.sqrt(p[:,0]**2 - p[:,1]**2 - p[:,2]**2 - p[:,3]**2)\n",
    "\n",
    "def npMass(p, ax=1):\n",
    "    return np.sqrt(p[:,0]**2 - p[:,1]**2 - p[:,2]**2 - p[:,3]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2432664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1080000, 4), (1080000, 4))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pa1.shape, pb2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ff9502",
   "metadata": {},
   "source": [
    "## Into PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53c38ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_momenta = [pa1, pa2, pb1, pb2, qc1, qc2]\n",
    "\n",
    "X = np.concatenate((pa1,pa2,pb1,pb2,qc1,qc2), axis=1)\n",
    "\n",
    "scaler = 1000\n",
    "torch_momenta = list(map(lambda x: torch.tensor(x/scaler, dtype=torch.float32), np.array_split(X, 6, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5d56b0",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bb87731",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeeLeMa(pl.LightningModule):\n",
    "    def __init__(self, hparams=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        hidden_layer       = hparams[\"hidden_layer\"]\n",
    "        hidden_depth       = hparams[\"hidden_depth\"]\n",
    "        learning_rate      = hparams[\"learning_rate\"]\n",
    "        batch_size         = hparams[\"batch_size\"]\n",
    "        \n",
    "        self.hidden_layer  = hidden_layer\n",
    "        self.hidden_depth  = hidden_depth\n",
    "        self.learning_rate = learning_rate\n",
    "        # self.max_lr        = hparams['max_lr']\n",
    "        self.batch_size    = batch_size\n",
    "        self.epochs        = hparams[\"epochs\"]\n",
    "        self.learn_mode    = hparams['learn_mode']   # for pT mC loss on off\n",
    "        self.squared_mass  = hparams['squared_mass'] # True or False\n",
    "        self.dist_fn       = hparams['dist_fn']      # l1 or l2\n",
    "        \n",
    "        m_C = torch.tensor(hparams[\"m_C_init\"])\n",
    "        m_B_add = torch.tensor(hparams[\"m_B_add\"])\n",
    "        m_A_add = torch.tensor(hparams[\"m_A_add\"])\n",
    "\n",
    "        m_B = m_C + m_B_add\n",
    "        m_A = m_B + m_A_add\n",
    "\n",
    "        if self.squared_mass == True:\n",
    "            m_C = m_C ** 2\n",
    "            m_B = m_B ** 2\n",
    "            m_A = m_A ** 2\n",
    "        \n",
    "        self.m_C = m_C\n",
    "        self.m_B_add = nn.Parameter(m_B_add, requires_grad=True)\n",
    "        self.m_A_add = nn.Parameter(m_A_add, requires_grad=True)\n",
    "        self.m_B = self.m_C + self.m_B_add\n",
    "        self.m_A = self.m_B + self.m_A_add\n",
    "        \n",
    "        layers = [nn.Linear(16, hidden_layer), nn.GELU(approximate='tanh')]\n",
    "        for i in range(hidden_depth):\n",
    "            layers.extend([\n",
    "                nn.Linear(hidden_layer, hidden_layer),\n",
    "                nn.GELU(approximate='tanh'),\n",
    "        ])\n",
    "\n",
    "        if self.learn_mode == 'pt_mc':\n",
    "            layers.append(nn.Linear(hidden_layer, 8))\n",
    "        elif self.learn_mode in ['pt', 'mc']:\n",
    "            layers.append(nn.Linear(hidden_layer, 6))\n",
    "        elif self.learn_mode == None:\n",
    "            layers.append(nn.Linear(hidden_layer, 4))\n",
    "                \n",
    "        self.net = nn.Sequential(*layers)\n",
    "        \n",
    "        self.save_hyperparameters(hparams)\n",
    "        \n",
    "        self.ds = None\n",
    "\n",
    "    def compute_mass(self):\n",
    "        self.m_B = self.m_C + F.elu(self.m_B_add) + 1\n",
    "        self.m_A = self.m_B + F.elu(self.m_A_add) + 1\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _, _ = batch\n",
    "        pa1 = x[:,0:4]\n",
    "        pa2 = x[:,4:8]\n",
    "        pb1 = x[:,8:12]\n",
    "        pb2 = x[:,12:16]\n",
    "        \n",
    "        q = self(x)\n",
    "        if self.learn_mode == 'pt_mc':\n",
    "            qc1 = q[:,0:4]\n",
    "            qc2 = q[:,4:8]\n",
    "        elif self.learn_mode == 'pt':\n",
    "            qx1 = q[:,0:1] \n",
    "            qy1 = q[:,1:2]\n",
    "            qx2 = q[:,2:3] \n",
    "            qy2 = q[:,3:4]\n",
    "            qz1 = q[:,4:5]   \n",
    "            qz2 = q[:,5:6]          \n",
    "            \n",
    "            Eq1 = torch.sqrt(self.m_C**2 + qx1**2 + qy1**2 + qz1**2)\n",
    "            Eq2 = torch.sqrt(self.m_C**2 + qx2**2 + qy2**2 + qz2**2)    \n",
    "            \n",
    "            qc1  = torch.cat([Eq1,qx1,qy1,qz1], 1)\n",
    "            qc2  = torch.cat([Eq2,qx2,qy2,qz2], 1) \n",
    "            \n",
    "        elif self.learn_mode == 'mc':\n",
    "            qx1 = q[:,0:1] \n",
    "            qy2 = q[:,1:2]\n",
    "            qz1 = q[:,2:3]   \n",
    "            qz2 = q[:,3:4]\n",
    "            Eq1 = q[:,4:5]\n",
    "            Eq2 = q[:,5:6]            \n",
    "\n",
    "            pTx = x[:,1:2]+x[:,5:6]+x[:,9:10]+x[:,13:14]\n",
    "            pTy = x[:,2:3]+x[:,6:7]+x[:,10:11]+x[:,14:15]\n",
    "\n",
    "            qx2 = -pTx-qx1\n",
    "            qy1 = -pTy-qy2\n",
    "\n",
    "            qc1  = torch.cat([Eq1,qx1,qy1,qz1], 1)\n",
    "            qc2  = torch.cat([Eq2,qx2,qy2,qz2], 1)    \n",
    "            \n",
    "        elif self.learn_mode == None:\n",
    "            qx1 = q[:,0:1] \n",
    "            qy2 = q[:,1:2]\n",
    "            qz1 = q[:,2:3]   \n",
    "            qz2 = q[:,3:4]\n",
    "\n",
    "            pTx = x[:,1:2]+x[:,5:6]+x[:,9:10]+x[:,13:14]\n",
    "            pTy = x[:,2:3]+x[:,6:7]+x[:,10:11]+x[:,14:15]\n",
    "\n",
    "            qx2 = -pTx-qx1\n",
    "            qy1 = -pTy-qy2\n",
    "\n",
    "            Eq1 = torch.sqrt(self.m_C**2 + qx1**2 + qy1**2 + qz1**2)\n",
    "            Eq2 = torch.sqrt(self.m_C**2 + qx2**2 + qy2**2 + qz2**2)\n",
    "\n",
    "            qc1  = torch.cat([Eq1,qx1,qy1,qz1], 1)\n",
    "            qc2  = torch.cat([Eq2,qx2,qy2,qz2], 1)        \n",
    "        \n",
    "        pB1 = pb1 + qc1\n",
    "        pB2 = pb2 + qc2\n",
    "        pA1 = pa1 + pB1\n",
    "        pA2 = pa2 + pB2\n",
    "        pT = (pA1 + pA2)[:,1:3]\n",
    "\n",
    "        if self.squared_mass == True:\n",
    "            mC1_sq = np_mass_sq(qc1)\n",
    "            mC2_sq = np_mass_sq(qc2)\n",
    "            mB1_sq = np_mass_sq(pB1)\n",
    "            mB2_sq = np_mass_sq(pB2)\n",
    "            mA1_sq = np_mass_sq(pA1)\n",
    "            mA2_sq = np_mass_sq(pA2)\n",
    "        else:\n",
    "            mC1_sq = Mass(qc1)\n",
    "            mC2_sq = Mass(qc2)\n",
    "            mB1_sq = Mass(pB1)\n",
    "            mB2_sq = Mass(pB2)\n",
    "            mA1_sq = Mass(pA1)\n",
    "            mA2_sq = Mass(pA2)\n",
    "\n",
    "        self.compute_mass()\n",
    "\n",
    "        mCs = self.m_C * torch.ones_like(mC1_sq)\n",
    "        mBs = self.m_B * torch.ones_like(mB1_sq)\n",
    "        mAs = self.m_A * torch.ones_like(mA1_sq)\n",
    "\n",
    "        if self.dist_fn == \"l1\":\n",
    "            loss_C = torch.abs(mC1_sq - mC2_sq) + torch.abs(mC1_sq - mCs) + torch.abs(mC2_sq - mCs)\n",
    "            loss_B = torch.abs(mB1_sq - mB2_sq) + torch.abs(mB1_sq - mBs) + torch.abs(mB2_sq - mBs)\n",
    "            loss_A = torch.abs(mA1_sq - mA2_sq) + torch.abs(mA1_sq - mAs) + torch.abs(mA2_sq - mAs)\n",
    "        elif self.dist_fn == \"l2\":\n",
    "            loss_C = torch.square(mC1_sq - mC2_sq) + torch.square(mC1_sq - mCs) + torch.square(mC2_sq - mCs)\n",
    "            loss_B = torch.square(mB1_sq - mB2_sq) + torch.square(mB1_sq - mBs) + torch.square(mB2_sq - mBs)\n",
    "            loss_A = torch.square(mA1_sq - mA2_sq) + torch.square(mA1_sq - mAs) + torch.square(mA2_sq - mAs)\n",
    "        \n",
    "        loss_pT = pT[:,0]**2 + pT[:,1]**2            \n",
    "        \n",
    "        loss_C = loss_C \n",
    "        loss_B = loss_B \n",
    "        loss_A = loss_A\n",
    "        \n",
    "        if self.learn_mode == 'pt_mc':\n",
    "            loss = (loss_A + loss_B + loss_C).mean() + loss_pT.mean()\n",
    "        elif self.learn_mode == 'pt':\n",
    "            loss = (loss_A + loss_B).mean() + loss_pT.mean()\n",
    "        elif self.learn_mode == 'mc':\n",
    "            loss = (loss_A + loss_B + loss_C).mean() \n",
    "        elif self.learn_mode == None:        \n",
    "            loss = (loss_A + loss_B).mean() \n",
    "                \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, _, _ = batch\n",
    "        pa1 = x[:,0:4]\n",
    "        pa2 = x[:,4:8]\n",
    "        pb1 = x[:,8:12]\n",
    "        pb2 = x[:,12:16]\n",
    "        \n",
    "        q = self(x)\n",
    "        if self.learn_mode == 'pt_mc':\n",
    "            qc1 = q[:,0:4]\n",
    "            qc2 = q[:,4:8]\n",
    "        elif self.learn_mode == 'pt':\n",
    "            qx1 = q[:,0:1] \n",
    "            qy1 = q[:,1:2]\n",
    "            qx2 = q[:,2:3]\n",
    "            qy2 = q[:,3:4]\n",
    "            qz1 = q[:,4:5]\n",
    "            qz2 = q[:,5:6]\n",
    "            \n",
    "            Eq1 = torch.sqrt(self.m_C**2 + qx1**2 + qy1**2 + qz1**2)\n",
    "            Eq2 = torch.sqrt(self.m_C**2 + qx2**2 + qy2**2 + qz2**2)\n",
    "            \n",
    "            qc1  = torch.cat([Eq1,qx1,qy1,qz1], 1)\n",
    "            qc2  = torch.cat([Eq2,qx2,qy2,qz2], 1)\n",
    "            \n",
    "        elif self.learn_mode == 'mc':\n",
    "            qx1 = q[:,0:1]\n",
    "            qy2 = q[:,1:2]\n",
    "            qz1 = q[:,2:3]\n",
    "            qz2 = q[:,3:4]\n",
    "            Eq1 = q[:,4:5]\n",
    "            Eq2 = q[:,5:6]\n",
    "\n",
    "            pTx = x[:,1:2]+x[:,5:6]+x[:,9:10]+x[:,13:14]\n",
    "            pTy = x[:,2:3]+x[:,6:7]+x[:,10:11]+x[:,14:15]\n",
    "\n",
    "            qx2 = -pTx-qx1\n",
    "            qy1 = -pTy-qy2\n",
    "\n",
    "            qc1  = torch.cat([Eq1,qx1,qy1,qz1], 1)\n",
    "            qc2  = torch.cat([Eq2,qx2,qy2,qz2], 1)\n",
    "            \n",
    "        elif self.learn_mode == None:\n",
    "            qx1 = q[:,0:1]\n",
    "            qy2 = q[:,1:2]\n",
    "            qz1 = q[:,2:3]\n",
    "            qz2 = q[:,3:4]\n",
    "\n",
    "            pTx = x[:,1:2]+x[:,5:6]+x[:,9:10]+x[:,13:14]\n",
    "            pTy = x[:,2:3]+x[:,6:7]+x[:,10:11]+x[:,14:15]\n",
    "\n",
    "            qx2 = -pTx-qx1\n",
    "            qy1 = -pTy-qy2\n",
    "\n",
    "            Eq1 = torch.sqrt(self.m_C**2 + qx1**2 + qy1**2 + qz1**2)\n",
    "            Eq2 = torch.sqrt(self.m_C**2 + qx2**2 + qy2**2 + qz2**2)\n",
    "\n",
    "            qc1  = torch.cat([Eq1,qx1,qy1,qz1], 1)\n",
    "            qc2  = torch.cat([Eq2,qx2,qy2,qz2], 1)\n",
    "        \n",
    "        pB1 = pb1 + qc1\n",
    "        pB2 = pb2 + qc2\n",
    "        pA1 = pa1 + pB1\n",
    "        pA2 = pa2 + pB2\n",
    "        pT = (pA1 + pA2)[:,1:3]\n",
    "\n",
    "        if self.squared_mass == True:\n",
    "            mC1_sq = np_mass_sq(qc1)\n",
    "            mC2_sq = np_mass_sq(qc2)\n",
    "            mB1_sq = np_mass_sq(pB1)\n",
    "            mB2_sq = np_mass_sq(pB2)\n",
    "            mA1_sq = np_mass_sq(pA1)\n",
    "            mA2_sq = np_mass_sq(pA2)\n",
    "        else:\n",
    "            mC1_sq = Mass(qc1)\n",
    "            mC2_sq = Mass(qc2)\n",
    "            mB1_sq = Mass(pB1)\n",
    "            mB2_sq = Mass(pB2)\n",
    "            mA1_sq = Mass(pA1)\n",
    "            mA2_sq = Mass(pA2)\n",
    "\n",
    "        self.compute_mass()\n",
    "\n",
    "        mCs = self.m_C * torch.ones_like(mC1_sq)\n",
    "        mBs = self.m_B * torch.ones_like(mB1_sq)\n",
    "        mAs = self.m_A * torch.ones_like(mA1_sq)\n",
    "        \n",
    "        if self.dist_fn == \"l1\":\n",
    "            loss_C = torch.abs(mC1_sq - mC2_sq) + torch.abs(mC1_sq - mCs) + torch.abs(mC2_sq - mCs)\n",
    "            loss_B = torch.abs(mB1_sq - mB2_sq) + torch.abs(mB1_sq - mBs) + torch.abs(mB2_sq - mBs)\n",
    "            loss_A = torch.abs(mA1_sq - mA2_sq) + torch.abs(mA1_sq - mAs) + torch.abs(mA2_sq - mAs)\n",
    "        elif self.dist_fn == \"l2\":\n",
    "            loss_C = torch.square(mC1_sq - mC2_sq) + torch.square(mC1_sq - mCs) + torch.square(mC2_sq - mCs)\n",
    "            loss_B = torch.square(mB1_sq - mB2_sq) + torch.square(mB1_sq - mBs) + torch.square(mB2_sq - mBs)\n",
    "            loss_A = torch.square(mA1_sq - mA2_sq) + torch.square(mA1_sq - mAs) + torch.square(mA2_sq - mAs)\n",
    "        \n",
    "        loss_pT = pT[:,0]**2 + pT[:,1]**2\n",
    "        \n",
    "        loss_C = loss_C\n",
    "        loss_B = loss_B\n",
    "        loss_A = loss_A\n",
    "        \n",
    "        if self.learn_mode == 'pt_mc':\n",
    "            loss = (loss_A + loss_B + loss_C).mean() + loss_pT.mean()\n",
    "        elif self.learn_mode == 'pt':\n",
    "            loss = (loss_A + loss_B).mean() + loss_pT.mean()\n",
    "        elif self.learn_mode == 'mc':\n",
    "            loss = (loss_A + loss_B + loss_C).mean() \n",
    "        elif self.learn_mode == None:        \n",
    "            loss = (loss_A + loss_B).mean()\n",
    "            \n",
    "        self.log('val_loss', loss)\n",
    "        self.log('loss_A', loss_A.mean())\n",
    "        self.log('loss_B', loss_B.mean())\n",
    "        self.log('loss_C', loss_C.mean())\n",
    "        self.log('loss_pT', loss_pT.mean())\n",
    "        self.log('m_A', self.m_A)\n",
    "        self.log('m_B', self.m_B)\n",
    "        self.log('m_C', self.m_C)\n",
    "        self.log('m_A1', mA1_sq.mean())\n",
    "        self.log('m_A2', mA2_sq.mean())\n",
    "        self.log('m_B1', mB1_sq.mean())\n",
    "        self.log('m_B2', mB2_sq.mean())\n",
    "        self.log('m_C1', mC1_sq.mean())\n",
    "        self.log('m_C2', mC2_sq.mean())\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(\n",
    "            self.parameters(),\n",
    "            lr=self.learning_rate,\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            # \"lr_scheduler\": {\n",
    "            #     \"scheduler\": OneCycleLR(\n",
    "            #         optimizer, \n",
    "            #         max_lr=self.max_lr,\n",
    "            #         steps_per_epoch=len(self.ds_train) // self.batch_size + 1,\n",
    "            #         epochs = self.epochs,\n",
    "            #     ),\n",
    "            #     \"interval\": \"step\",\n",
    "            #     \"monitor\": \"val_loss\",\n",
    "            #     \"strict\": True,\n",
    "            # }\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": PolynomialLR(\n",
    "                    optimizer,\n",
    "                    total_iters = self.epochs,\n",
    "                    power = 2.0\n",
    "                ),\n",
    "                \"interval\": \"epoch\",\n",
    "                \"monitor\": \"val_loss\",\n",
    "                \"strict\": True,\n",
    "            }\n",
    "            # \"lr_scheduler\": CosineAnnealingLR(\n",
    "            #    optimizer,\n",
    "            #    T_max=self.epochs,\n",
    "            #    eta_min=self.learning_rate / 100\n",
    "            # )\n",
    "            # \"lr_scheduler\": CosineAnnealingWarmRestarts(\n",
    "            #    optimizer,\n",
    "            #    T_0=self.t0,\n",
    "            #    T_mult=1,\n",
    "            #    eta_min=0\n",
    "            # )\n",
    "        }\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        self.ds = ToyData(*torch_momenta)\n",
    "        self.N = len(self.ds)\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        N_train = self.N // 10 * 8\n",
    "        N_val = self.N - N_train\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            self.ds_train, self.ds_val = random_split(self.ds, [N_train, N_val])\n",
    "        if stage == \"test\" or stage is None:\n",
    "            _, self.ds_test = random_split(self.ds, [N_train, N_val])\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.ds_train, batch_size=self.batch_size)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.ds_val, batch_size=self.batch_size)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.ds_test, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d1f65f",
   "metadata": {},
   "source": [
    "## Hyper-parameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e65567dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = 700/scaler \n",
    "\n",
    "hparams = {\n",
    "    \"hidden_layer\": 256,\n",
    "    \"hidden_depth\": 5,\n",
    "    \"learning_rate\": 1e-2,\n",
    "    \"max_lr\": 1e-2,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"m_C_init\": mc,\n",
    "    \"m_B_add\": 0.3,\n",
    "    \"m_A_add\": 0.3,\n",
    "    \"epochs\": 100,\n",
    "    \"dist_fn\": \"l1\",       # 'l1', 'l2'\n",
    "    \"learn_mode\": None,    # 'pt_mc', 'mc', 'pt', None\n",
    "    \"squared_mass\": False, # True, False // Note: If False, ONLY 'pt' and None are available for the physical reason.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b4afc48-5707-4e1b-9480-b94c0e7d07a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeeLeMa(\n",
    "    hparams=hparams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0dc289d5-aa2b-4f58-9cc7-3f436fc58c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "DeeLeMa                                  2\n",
       "├─Sequential: 1-1                        --\n",
       "│    └─Linear: 2-1                       4,352\n",
       "│    └─GELU: 2-2                         --\n",
       "│    └─Linear: 2-3                       65,792\n",
       "│    └─GELU: 2-4                         --\n",
       "│    └─Linear: 2-5                       65,792\n",
       "│    └─GELU: 2-6                         --\n",
       "│    └─Linear: 2-7                       65,792\n",
       "│    └─GELU: 2-8                         --\n",
       "│    └─Linear: 2-9                       65,792\n",
       "│    └─GELU: 2-10                        --\n",
       "│    └─Linear: 2-11                      65,792\n",
       "│    └─GELU: 2-12                        --\n",
       "│    └─Linear: 2-13                      1,028\n",
       "=================================================================\n",
       "Total params: 334,342\n",
       "Trainable params: 334,342\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f3ef790",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "model = DeeLeMa(\n",
    "    hparams=hparams\n",
    ")\n",
    "\n",
    "tb_logger = TensorBoardLogger(save_dir=\"logs/\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=hparams[\"epochs\"],\n",
    "    logger=tb_logger,\n",
    "    devices=[0],\n",
    "    enable_progress_bar=False,\n",
    "    callbacks=[\n",
    "        LearningRateMonitor(logging_interval=\"step\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd63028",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af284cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3050 4GB Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | net  | Sequential | 334 K \n",
      "------------------------------------\n",
      "334 K     Trainable params\n",
      "0         Non-trainable params\n",
      "334 K     Total params\n",
      "1.337     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11a341ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint('DeeLeMa_Toy_ELU.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
